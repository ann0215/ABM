{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import toml\n",
    "import numpy as np\n",
    "from numba import njit\n",
    "from typing import Dict, List, Tuple\n",
    "from abc import ABC, abstractmethod\n",
    "from contextlib import contextmanager\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as mpl_animation\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from matplotlib.patches import Circle, Polygon\n",
    "from matplotlib.collections import PatchCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### config\n",
    "\n",
    "class Config:\n",
    "    \"\"\"Config loading and updating\n",
    "    Attribute\n",
    "    -------------\n",
    "    config: dict\n",
    "\n",
    "    Methods\n",
    "    -------------\n",
    "    from_dict: update from a dict\n",
    "    load_config: update from file\n",
    "    sub_config: return a sub dict wrapped in Config()\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config=None) -> None:\n",
    "        self.config = {}\n",
    "        if config:\n",
    "            self.config = config\n",
    "\n",
    "    def from_dict(self, config: Dict) -> None:\n",
    "        \"\"\"Update from dict\"\"\"\n",
    "        self.config.update(config)\n",
    "\n",
    "    def load_config(self, filename: str) -> None:\n",
    "        \"\"\"update from file\"\"\"\n",
    "        user_config = toml.load(filename)\n",
    "        self.from_dict(user_config)\n",
    "\n",
    "    def sub_config(self, field_name: str) -> \"Config\":\n",
    "        \"\"\"return a sub dict wrapped in Config()\"\"\"\n",
    "        sub_dict = self.config.get(field_name)\n",
    "        if isinstance(sub_dict, dict):\n",
    "            return Config(sub_dict)\n",
    "        return Config()\n",
    "\n",
    "    def __call__(self, entry: str, default=None):\n",
    "        return self.config.get(entry) or default\n",
    "\n",
    "\n",
    "class DefaultConfig(Config):\n",
    "    \"\"\"Default configs\"\"\"\n",
    "\n",
    "    CONFIG = \"\"\"\n",
    "    title = \"Social Force Default Config File\"\n",
    "\n",
    "    [scene]\n",
    "    enable_group = true\n",
    "    agent_radius = 0.35\n",
    "    step_width = 1.0\n",
    "    max_speed_multiplier = 1.5\n",
    "    tau = 0.5\n",
    "    resolution = 10\n",
    "\n",
    "    [group_coherence_force]\n",
    "    factor = 1.0\n",
    "\n",
    "    [group_repulsive_force]\n",
    "    factor = 1.0\n",
    "    threshold = 0.55\n",
    "\n",
    "    [group_gaze_force]\n",
    "    factor = 1.0\n",
    "    # fov params\n",
    "    fov_phi = 90.0\n",
    "\n",
    "    [desired_force]\n",
    "    factor = 1.0\n",
    "    relaxation_time = 0.5\n",
    "    mass = 80\n",
    "\n",
    "    [social_force]\n",
    "    factor = 1.0\n",
    "    param_A = 2000\n",
    "    param_B = 0.08\n",
    "    param_k = 800\n",
    "    kappa = 500\n",
    "\n",
    "    [obstacle_force]\n",
    "    factor = 1.0\n",
    "    param_A = 2000\n",
    "    param_B = 0.08\n",
    "    param_k = 800\n",
    "    kappa = 500\n",
    "\n",
    "    [along_wall_force]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__(toml.loads(self.CONFIG))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### forces\n",
    "\n",
    "def camel_to_snake(camel_case_string):\n",
    "    \"\"\"Convert CamelCase to snake_case\"\"\"\n",
    "\n",
    "    return re.sub(r\"(?<!^)(?=[A-Z])\", \"_\", camel_case_string).lower()\n",
    "\n",
    "\n",
    "class Force(ABC):\n",
    "    \"\"\"Force base class\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.scene = None\n",
    "        self.peds = None\n",
    "        self.factor = 1.0\n",
    "        self.config = Config()\n",
    "\n",
    "    def init(self, scene, config):\n",
    "        \"\"\"Load config and scene\"\"\"\n",
    "        # load the sub field corresponding to the force name from global confgi file\n",
    "        self.config = config.sub_config(camel_to_snake(type(self).__name__))\n",
    "        if self.config:\n",
    "            self.factor = self.config(\"factor\", 1.0)\n",
    "\n",
    "        self.scene = scene\n",
    "        self.peds = self.scene.peds\n",
    "\n",
    "    @abstractmethod\n",
    "    def _get_force(self) -> np.ndarray:\n",
    "        \"\"\"Abstract class to get social forces\n",
    "            return: an array of force vectors for each pedestrians\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def get_force(self, debug=False):\n",
    "        force = self._get_force()\n",
    "        if debug:\n",
    "            logger.debug(f\"{camel_to_snake(type(self).__name__)}:\\n {repr(force)}\")\n",
    "        return force\n",
    "\n",
    "\n",
    "\n",
    "class GroupCoherenceForce(Force):\n",
    "    \"\"\" Alternative group coherence force as specified in pedsim_ros\"\"\"\n",
    "\n",
    "    def _get_force(self):\n",
    "        forces = np.zeros((self.peds.size(), 2))\n",
    "        if self.peds.has_group():\n",
    "            for group in self.peds.groups:\n",
    "                threshold = (len(group) - 1) / 2\n",
    "                member_pos = self.peds.pos()[group, :]\n",
    "                com = center_of_mass(member_pos)\n",
    "                force_vec = com - member_pos\n",
    "                norms = speeds(force_vec)\n",
    "                softened_factor = (np.tanh(norms - threshold) + 1) / 2\n",
    "                forces[group, :] += (force_vec.T * softened_factor).T\n",
    "        return forces * self.factor\n",
    "\n",
    "\n",
    "class GroupRepulsiveForce(Force):\n",
    "    \"\"\"Group repulsive force\"\"\"\n",
    "\n",
    "    def _get_force(self):\n",
    "        threshold = self.config(\"threshold\", 0.1)\n",
    "        forces = np.zeros((self.peds.size(), 2))\n",
    "        if self.peds.has_group():\n",
    "            for group in self.peds.groups:\n",
    "                size = len(group)\n",
    "                member_pos = self.peds.pos()[group, :]\n",
    "                diff = each_diff(member_pos)  # others - self\n",
    "                _, norms = normalize(diff)\n",
    "                diff[norms > threshold, :] = 0\n",
    "                forces[group, :] += np.sum(diff.reshape((size, -1, 2)), axis=1)\n",
    "\n",
    "        return forces * self.factor\n",
    "\n",
    "\n",
    "\n",
    "class GroupGazeForce(Force):\n",
    "    \"\"\"Group gaze force\"\"\"\n",
    "\n",
    "    def _get_force(self):\n",
    "        forces = np.zeros((self.peds.size(), 2))\n",
    "        directions, dist = desired_directions(self.peds.state)\n",
    "        if self.peds.has_group():\n",
    "            for group in self.peds.groups:\n",
    "                group_size = len(group)\n",
    "                # 1-agent groups don't need to compute this\n",
    "                if group_size <= 1:\n",
    "                    continue\n",
    "                member_pos = self.peds.pos()[group, :]\n",
    "                member_directions = directions[group, :]\n",
    "                member_dist = dist[group]\n",
    "                # use center of mass without the current agent\n",
    "                relative_com = np.array(\n",
    "                    [\n",
    "                        center_of_mass(member_pos[np.arange(group_size) != i, :2])\n",
    "                        - member_pos[i, :]\n",
    "                        for i in range(group_size)\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "                com_directions, com_dist = normalize(relative_com)\n",
    "                # angle between walking direction and center of mass\n",
    "                element_prod = np.array(\n",
    "                    [np.dot(d, c) for d, c in zip(member_directions, com_directions)]\n",
    "                )\n",
    "                force = (\n",
    "                    com_dist.reshape(-1, 1)\n",
    "                    * element_prod.reshape(-1, 1)\n",
    "                    / member_dist.reshape(-1, 1)\n",
    "                    * member_directions\n",
    "                )\n",
    "                forces[group, :] += force\n",
    "\n",
    "        return forces * self.factor\n",
    "\n",
    "\n",
    "class DesiredForce(Force):\n",
    "    \"\"\"Calculates the force between this agent and the next assigned waypoint.\n",
    "    :return: the calculated force\n",
    "    \"\"\"\n",
    "\n",
    "    def _get_force(self):\n",
    "        relaxation_time = self.config(\"relaxation_time\", 0.5)\n",
    "        mass = self.config(\"mass\", 80)\n",
    "        pos = self.peds.pos()\n",
    "        vel = self.peds.vel()\n",
    "        goal = self.peds.goal()\n",
    "        direction, _ = normalize(goal - pos)\n",
    "        force = np.zeros((self.peds.size(), 2))\n",
    "\n",
    "        desired_speed = direction * self.peds.max_speeds.reshape((-1, 1))\n",
    "        force = mass * (desired_speed - vel.reshape((-1, 2))) / relaxation_time\n",
    "        return force * self.factor\n",
    "    \n",
    "\n",
    "class SocialForce(Force):\n",
    "    \"\"\"Calculates the social force between this agent and all the other agents\n",
    "    belonging to the same scene.\n",
    "    :return:  nx2 ndarray the calculated force\n",
    "    \"\"\"\n",
    "\n",
    "    def _get_force(self):\n",
    "        param_A = self.config(\"param_A\", 2000)\n",
    "        param_B = self.config(\"param_B\", 0.08)\n",
    "        param_k = self.config(\"param_k\", 12000)\n",
    "        kappa = self.config(\"kappa\", 24000)\n",
    "\n",
    "        pos_diff = - each_diff(self.peds.pos())  # n*(n-1)x2 self - other\n",
    "        n_ij, diff_length = normalize(pos_diff)\n",
    "        diff_length = diff_length.reshape(-1, 1)\n",
    "        vel_diff = - each_diff(self.peds.vel())\n",
    "        t_ij = np.column_stack((-n_ij[:, 1], n_ij[:, 0]))\n",
    "        delta_vel_ji = - vel_diff * t_ij\n",
    "        distance = 2*self.peds.agent_radius - diff_length\n",
    "        force = np.where(\n",
    "            distance < 0,\n",
    "            (param_A * np.exp(distance / param_B) + param_k * distance) * n_ij + kappa * distance * delta_vel_ji * t_ij,\n",
    "            param_A * n_ij\n",
    "        )\n",
    "\n",
    "        force = np.sum(force.reshape((self.peds.size(), -1, 2)), axis=1)\n",
    "        return force * self.factor\n",
    "    \n",
    "\n",
    "class ObstacleForce(Force):\n",
    "    \"\"\"Calculates the force between this agent and the nearest obstacle in this\n",
    "    scene.\n",
    "    :return:  the calculated force\n",
    "    \"\"\"\n",
    "\n",
    "    def _get_force(self):\n",
    "        param_A = self.config(\"param_A\", 2000)\n",
    "        param_B = self.config(\"param_B\", 0.08)\n",
    "        param_k = self.config(\"param_k\", 12000)\n",
    "        kappa = self.config(\"kappa\", 24000)\n",
    "\n",
    "        force = np.zeros((self.peds.size(), 2))\n",
    "        if len(self.scene.get_obstacles()) == 0:\n",
    "            return force\n",
    "        obstacles = np.vstack(self.scene.get_obstacles())\n",
    "        pos = self.peds.pos()\n",
    "        vel = self.peds.vel()\n",
    "        agent_radius = self.peds.agent_radius\n",
    "\n",
    "        for i, p in enumerate(pos):\n",
    "            pos_diff = p - obstacles\n",
    "            n_iW, diff_length = normalize(pos_diff)\n",
    "            diff_length = diff_length.reshape(-1, 1)\n",
    "\n",
    "            t_iW = np.hstack((-(n_iW)[:, 1].reshape(-1, 1), (n_iW)[:, 0].reshape(-1, 1)))\n",
    "            delta_vel_Wi = np.dot(vel[i], t_iW.T).reshape(-1, 1)\n",
    "            distance = 2 * agent_radius - diff_length\n",
    "\n",
    "            # Calculate the force for each obstacle\n",
    "            obstacle_force = np.where(\n",
    "                distance < 0,\n",
    "                (param_A * np.exp(distance / param_B) + param_k * distance) * n_iW + kappa * distance * delta_vel_Wi * t_iW,\n",
    "                param_A * n_iW\n",
    "            )\n",
    "\n",
    "            # Sum up the forces from all obstacles\n",
    "            force[i] = np.sum(obstacle_force, axis=0)\n",
    "\n",
    "        return force * self.factor\n",
    "    \n",
    "\n",
    "\n",
    "### stateutil\n",
    "\n",
    "@njit\n",
    "def normalize(vecs: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Normalize nx2 array along the second axis\n",
    "    input: [n,2] ndarray\n",
    "    output: (normalized vectors, norm factors)\n",
    "    \"\"\"\n",
    "    norm_factors = []\n",
    "    for line in vecs:\n",
    "        norm_factors.append(np.linalg.norm(line))\n",
    "    norm_factors = np.array(norm_factors)\n",
    "    normalized = vecs / np.expand_dims(norm_factors, -1)\n",
    "    # get rid of nans\n",
    "    for i in range(norm_factors.shape[0]):\n",
    "        if norm_factors[i] == 0:\n",
    "            normalized[i] = np.zeros(vecs.shape[1])\n",
    "    return normalized, norm_factors\n",
    "\n",
    "\n",
    "@njit\n",
    "def desired_directions(state: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Given the current state and destination, compute desired direction.\"\"\"\n",
    "    destination_vectors = state[:, 4:6] - state[:, 0:2]\n",
    "    directions, dist = normalize(destination_vectors)\n",
    "    return directions, dist\n",
    "\n",
    "\n",
    "@njit\n",
    "def vec_diff(vecs: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"r_ab\n",
    "    r_ab := r_a - r_b.\n",
    "    \"\"\"\n",
    "    diff = np.expand_dims(vecs, 1) - np.expand_dims(vecs, 0)\n",
    "    return diff\n",
    "\n",
    "\n",
    "def each_diff(vecs: np.ndarray, keepdims=False) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    :param vecs: nx2 array\n",
    "    :return: diff with diagonal elements removed\n",
    "    \"\"\"\n",
    "    diff = vec_diff(vecs)\n",
    "    # diff = diff[np.any(diff, axis=-1), :]  # get rid of zero vectors\n",
    "    diff = diff[\n",
    "        ~np.eye(diff.shape[0], dtype=bool), :\n",
    "    ]  # get rif of diagonal elements in the diff matrix\n",
    "    if keepdims:\n",
    "        diff = diff.reshape(vecs.shape[0], -1, vecs.shape[1])\n",
    "\n",
    "    return diff\n",
    "\n",
    "\n",
    "@njit\n",
    "def speeds(state: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Return the speeds corresponding to a given state.\"\"\"\n",
    "    state = state.astype(np.float64)\n",
    "    speed_vecs = state[:, 2:4]\n",
    "    speeds_array = np.empty(state.shape[0], dtype=np.float64)\n",
    "    for i in range(state.shape[0]):\n",
    "        speeds_array[i] = np.linalg.norm(speed_vecs[i])\n",
    "    return speeds_array\n",
    "\n",
    "\n",
    "@njit\n",
    "def center_of_mass(vecs: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Center-of-mass of a given group\"\"\"\n",
    "    return np.sum(vecs, axis=0) / vecs.shape[0]\n",
    "\n",
    "\n",
    "\n",
    "### scene\n",
    "\n",
    "class PedState:\n",
    "    \"\"\"Tracks the state of pedstrains and social groups\"\"\"\n",
    "\n",
    "    def __init__(self, state, groups, config):\n",
    "        self.default_tau = config(\"tau\", 0.5)\n",
    "        self.step_width = config(\"step_width\", 0.4)\n",
    "        self.agent_radius = config(\"agent_radius\", 0.35)\n",
    "        self.max_speed_multiplier = config(\"max_speed_multiplier\", 1.5)\n",
    "\n",
    "        self.max_speeds = None\n",
    "        self.initial_speeds = None\n",
    "\n",
    "        self.ped_states = []\n",
    "        self.group_states = []\n",
    "\n",
    "        self.update(state, groups)\n",
    "\n",
    "    def update(self, state, groups):\n",
    "        self.state = state\n",
    "        self.groups = groups\n",
    "\n",
    "    @property\n",
    "    def state(self):\n",
    "        return self._state\n",
    "\n",
    "    @state.setter\n",
    "    def state(self, state):\n",
    "        tau = self.default_tau * np.ones(state.shape[0])\n",
    "        if state.shape[1] < 7:\n",
    "            self._state = np.concatenate((state, np.expand_dims(tau, -1)), axis=-1)\n",
    "        else:\n",
    "            self._state = state\n",
    "        if self.initial_speeds is None:\n",
    "            self.initial_speeds = self.speeds()\n",
    "        self.max_speeds = self.max_speed_multiplier * self.initial_speeds\n",
    "        self.ped_states.append(self._state.copy())\n",
    "\n",
    "    def get_states(self):\n",
    "        return np.stack(self.ped_states), self.group_states\n",
    "\n",
    "    def size(self) -> int:\n",
    "        return self.state.shape[0]\n",
    "\n",
    "    def pos(self) -> np.ndarray:\n",
    "        return self.state[:, 0:2]\n",
    "\n",
    "    def vel(self) -> np.ndarray:\n",
    "        return self.state[:, 2:4]\n",
    "\n",
    "    def goal(self) -> np.ndarray:\n",
    "        return self.state[:, 4:6]\n",
    "\n",
    "    def tau(self):\n",
    "        return self.state[:, 6:7]\n",
    "\n",
    "    def speeds(self):\n",
    "        \"\"\"Return the speeds corresponding to a given state.\"\"\"\n",
    "        return speeds(self.state)\n",
    "\n",
    "    def step(self, force, groups=None):\n",
    "        \"\"\"Move peds according to forces\"\"\"\n",
    "        # desired velocity\n",
    "        desired_velocity = self.vel() + self.step_width * force\n",
    "        desired_velocity = self.capped_velocity(desired_velocity, self.max_speeds)\n",
    "        # stop when arrived\n",
    "        desired_velocity[desired_directions(self.state)[1] < 0.5] = [0, 0]\n",
    "\n",
    "        # update state\n",
    "        next_state = self.state\n",
    "        next_state[:, 0:2] += desired_velocity * self.step_width\n",
    "        next_state[:, 2:4] = desired_velocity\n",
    "        next_groups = self.groups\n",
    "        if groups is not None:\n",
    "            next_groups = groups\n",
    "        self.update(next_state, next_groups)\n",
    "\n",
    "    def desired_directions(self):\n",
    "        return desired_directions(self.state)[0]\n",
    "\n",
    "    @staticmethod\n",
    "    def capped_velocity(desired_velocity, max_velocity):\n",
    "        \"\"\"Scale down a desired velocity to its capped speed.\"\"\"\n",
    "        desired_speeds = np.linalg.norm(desired_velocity, axis=-1)\n",
    "        factor = np.minimum(1.0, max_velocity / desired_speeds)\n",
    "        factor[desired_speeds == 0] = 0.0\n",
    "        return desired_velocity * np.expand_dims(factor, -1)\n",
    "\n",
    "    @property\n",
    "    def groups(self) -> List[List]:\n",
    "        return self._groups\n",
    "\n",
    "    @groups.setter\n",
    "    def groups(self, groups: List[List]):\n",
    "        if groups is None:\n",
    "            self._groups = []\n",
    "        else:\n",
    "            self._groups = groups\n",
    "        self.group_states.append(self._groups.copy())\n",
    "\n",
    "    def has_group(self):\n",
    "        return self.groups is not None\n",
    "\n",
    "    def which_group(self, index: int) -> int:\n",
    "        \"\"\"find group index from ped index\"\"\"\n",
    "        for i, group in enumerate(self.groups):\n",
    "            if index in group:\n",
    "                return i\n",
    "        return -1\n",
    "\n",
    "\n",
    "class EnvState:\n",
    "    \"\"\"State of the environment obstacles\"\"\"\n",
    "\n",
    "    def __init__(self, obstacles, resolution=10):\n",
    "        self.resolution = resolution\n",
    "        self.obstacles = obstacles\n",
    "\n",
    "    @property\n",
    "    def obstacles(self) -> List[np.ndarray]:\n",
    "        \"\"\"obstacles is a list of np.ndarray\"\"\"\n",
    "        return self._obstacles\n",
    "\n",
    "    @obstacles.setter\n",
    "    def obstacles(self, obstacles):\n",
    "        \"\"\"Input an list of (startx, endx, starty, endy) as start and end of a line\"\"\"\n",
    "        if obstacles is None:\n",
    "            self._obstacles = []\n",
    "        else:\n",
    "            self._obstacles = []\n",
    "            for startx, endx, starty, endy in obstacles:\n",
    "                samples = int(np.linalg.norm((startx - endx, starty - endy)) * self.resolution)\n",
    "                line = np.array(\n",
    "                    list(\n",
    "                        zip(np.linspace(startx, endx, samples), np.linspace(starty, endy, samples))\n",
    "                    )\n",
    "                )\n",
    "                self._obstacles.append(line)\n",
    "\n",
    "\n",
    "                \n",
    "\n",
    "# simulator\n",
    "\n",
    "class Simulator:\n",
    "    \"\"\"Simulate social force model.\n",
    "\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    state : np.ndarray [n, 6] or [n, 7]\n",
    "       Each entry represents a pedestrian state, (x, y, v_x, v_y, d_x, d_y, [tau])\n",
    "    obstacles : np.ndarray\n",
    "        Environmental obstacles\n",
    "    groups : List of Lists\n",
    "        Group members are denoted by their indices in the state\n",
    "    config : Dict\n",
    "        Loaded from a toml config file\n",
    "    max_speeds : np.ndarray\n",
    "        Maximum speed of pedestrians\n",
    "    forces : List\n",
    "        Forces to factor in during navigation\n",
    "\n",
    "    Methods\n",
    "    ---------\n",
    "    capped_velocity(desired_velcity)\n",
    "        Scale down a desired velocity to its capped speed\n",
    "    step()\n",
    "        Make one step\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, state, groups=None, obstacles=None, config_file=None):\n",
    "        self.config = DefaultConfig()\n",
    "        if config_file:\n",
    "            self.config.load_config(config_file)\n",
    "        # TODO: load obstacles from config\n",
    "        self.scene_config = self.config.sub_config(\"scene\")\n",
    "        # initiate obstacles\n",
    "        self.env = EnvState(obstacles, self.config(\"resolution\", 10.0))\n",
    "\n",
    "        # initiate agents\n",
    "        self.peds = PedState(state, groups, self.config)\n",
    "\n",
    "        # construct forces\n",
    "        self.forces = self.make_forces(self.config)\n",
    "\n",
    "    def make_forces(self, force_configs):\n",
    "        \"\"\"Construct forces\"\"\"\n",
    "        force_list = [\n",
    "            DesiredForce(),\n",
    "            SocialForce(),\n",
    "            ObstacleForce(),\n",
    "        ]\n",
    "        group_forces = [\n",
    "            GroupCoherenceForce(),\n",
    "            GroupRepulsiveForce(),\n",
    "            GroupGazeForce(),\n",
    "        ]\n",
    "        if self.scene_config(\"enable_group\"):\n",
    "            force_list += group_forces\n",
    "\n",
    "        # initiate forces\n",
    "        for force in force_list:\n",
    "            force.init(self, force_configs)\n",
    "\n",
    "        return force_list\n",
    "\n",
    "    def compute_forces(self):\n",
    "        \"\"\"compute forces\"\"\"\n",
    "        return sum(map(lambda x: x.get_force(), self.forces))\n",
    "\n",
    "    def get_states(self):\n",
    "        \"\"\"Expose whole state\"\"\"\n",
    "        return self.peds.get_states()\n",
    "\n",
    "    def get_length(self):\n",
    "        \"\"\"Get simulation length\"\"\"\n",
    "        return len(self.get_states()[0])\n",
    "\n",
    "    def get_obstacles(self):\n",
    "        return self.env.obstacles\n",
    "\n",
    "    def step_once(self):\n",
    "        \"\"\"step once\"\"\"\n",
    "        self.peds.step(self.compute_forces())\n",
    "\n",
    "    def step(self, n=1):\n",
    "        \"\"\"Step n time\"\"\"\n",
    "        for _ in range(n):\n",
    "            self.step_once()\n",
    "        return self\n",
    "    \n",
    "\n",
    "\n",
    "### plot\n",
    "\n",
    "@contextmanager\n",
    "def canvas(image_file=None, **kwargs):\n",
    "    \"\"\"Generic matplotlib context.\"\"\"\n",
    "    fig, ax = plt.subplots(**kwargs)\n",
    "    ax.grid(linestyle=\"dotted\")\n",
    "    ax.set_aspect(1.0, \"datalim\")\n",
    "    ax.set_axisbelow(True)\n",
    "\n",
    "    yield ax\n",
    "\n",
    "    fig.set_tight_layout(True)\n",
    "    if image_file:\n",
    "        fig.savefig(image_file, dpi=300)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def animation(length: int, movie_file=None, writer=None, **kwargs):\n",
    "    \"\"\"Context for animations.\"\"\"\n",
    "    fig, ax = plt.subplots(**kwargs)\n",
    "    fig.set_tight_layout(True)\n",
    "    ax.grid(linestyle=\"dotted\")\n",
    "    ax.set_aspect(1.0, \"datalim\")\n",
    "    ax.set_axisbelow(True)\n",
    "\n",
    "    context = {\"ax\": ax, \"update_function\": None, \"init_function\": None}\n",
    "    yield context\n",
    "\n",
    "    ani = mpl_animation.FuncAnimation(\n",
    "        fig,\n",
    "        init_func=context[\"init_function\"],\n",
    "        func=context[\"update_function\"],\n",
    "        frames=length,\n",
    "        blit=True,\n",
    "    )\n",
    "    if movie_file:\n",
    "        ani.save(movie_file, writer=writer)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "\n",
    "class SceneVisualizer:\n",
    "    \"\"\"Context for social nav visualization\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, scene, output=None, writer=\"imagemagick\", cmap=\"viridis\", agent_colors=None, **kwargs\n",
    "    ):\n",
    "        self.scene = scene\n",
    "        self.states, self.group_states = self.scene.get_states()\n",
    "        self.cmap = cmap\n",
    "        self.agent_colors = agent_colors\n",
    "        self.frames = self.scene.get_length()\n",
    "        self.output = output\n",
    "        self.writer = writer\n",
    "\n",
    "        self.fig, self.ax = plt.subplots(**kwargs)\n",
    "\n",
    "        self.ani = None\n",
    "\n",
    "        self.group_actors = None\n",
    "        self.group_collection = PatchCollection([])\n",
    "        self.group_collection.set(\n",
    "            animated=True,\n",
    "            alpha=0.2,\n",
    "            cmap=self.cmap,\n",
    "            facecolors=\"none\",\n",
    "            edgecolors=\"purple\",\n",
    "            linewidth=2,\n",
    "            clip_on=True,\n",
    "        )\n",
    "\n",
    "        self.human_actors = None\n",
    "        self.human_collection = PatchCollection([])\n",
    "        self.human_collection.set(animated=True, alpha=0.6, cmap=self.cmap, clip_on=True)\n",
    "\n",
    "    def plot(self):\n",
    "        \"\"\"Main method for create plot\"\"\"\n",
    "        self.plot_obstacles()\n",
    "        groups = self.group_states[0]  # static group for now\n",
    "        if not groups:\n",
    "            for ped in range(self.scene.peds.size()):\n",
    "                x = self.states[:, ped, 0]\n",
    "                y = self.states[:, ped, 1]\n",
    "                self.ax.plot(x, y, \"-o\", label=f\"ped {ped}\", markersize=2.5)\n",
    "        else:\n",
    "            colors = plt.cm.rainbow(np.linspace(0, 1, len(groups)))\n",
    "            for i, group in enumerate(groups):\n",
    "                for ped in group:\n",
    "                    x = self.states[:, ped, 0]\n",
    "                    y = self.states[:, ped, 1]\n",
    "                    self.ax.plot(x, y, \"-o\", label=f\"ped {ped}\", markersize=2.5, color=colors[i])\n",
    "        self.ax.legend()\n",
    "        return self.fig\n",
    "\n",
    "    def animate(self):\n",
    "        \"\"\"Main method to create animation\"\"\"\n",
    "        self.ani = FuncAnimation(\n",
    "            self.fig,\n",
    "            init_func=self.animation_init,\n",
    "            func=self.animation_update,\n",
    "            frames=self.frames,\n",
    "            blit=True,\n",
    "        )\n",
    "        return self.ani\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.fig.set_tight_layout(True)\n",
    "        self.ax.grid(linestyle=\"dotted\")\n",
    "        self.ax.set_aspect(\"equal\")\n",
    "        self.ax.margins(2.0)\n",
    "        self.ax.set_axisbelow(True)\n",
    "        self.ax.set_xlabel(\"x [m]\")\n",
    "        self.ax.set_ylabel(\"y [m]\")\n",
    "\n",
    "        plt.rcParams[\"animation.html\"] = \"jshtml\"\n",
    "\n",
    "        self.ax.set(xlim=(-2, 12), ylim=(-2, 12))\n",
    "\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        if self.output:\n",
    "            if self.ani:\n",
    "                output = self.output + \".gif\"\n",
    "                self.ani.save(output, writer=self.writer)\n",
    "            else:\n",
    "                output = self.output + \".png\"\n",
    "                self.fig.savefig(output, dpi=300)\n",
    "        plt.close(self.fig)\n",
    "\n",
    "    def plot_human(self, step=-1):\n",
    "        \"\"\"Generate patches for human\n",
    "        :param step: index of state, default is the latest\n",
    "        :return: list of patches\n",
    "        \"\"\"\n",
    "        states, _ = self.scene.get_states()\n",
    "        current_state = states[step]\n",
    "        radius = [0.2] * current_state.shape[0]\n",
    "        if self.human_actors:\n",
    "            for i, human in enumerate(self.human_actors):\n",
    "                human.center = current_state[i, :2]\n",
    "                human.set_radius(0.2)\n",
    "        else:\n",
    "            self.human_actors = [\n",
    "                Circle(pos, r) for pos, r in zip(current_state[:, :2], radius)\n",
    "            ]\n",
    "        self.human_collection.set_paths(self.human_actors)\n",
    "        if not self.agent_colors:\n",
    "            self.human_collection.set_array(np.arange(current_state.shape[0]))\n",
    "        else:\n",
    "            assert len(self.human_actors) == len(\n",
    "                self.agent_colors\n",
    "            ), \"agent_colors must be the same length as the agents\"\n",
    "            self.human_collection.set_facecolor(self.agent_colors)\n",
    "\n",
    "    def plot_groups(self, step=-1):\n",
    "        \"\"\"Generate patches for groups\n",
    "        :param step: index of state, default is the latest\n",
    "        :return: list of patches\n",
    "        \"\"\"\n",
    "        states, group_states = self.scene.get_states()\n",
    "        current_state = states[step]\n",
    "        current_groups = group_states[step]\n",
    "        if self.group_actors:  # update patches, else create\n",
    "            points = [current_state[g, :2] for g in current_groups]\n",
    "            for i, p in enumerate(points):\n",
    "                self.group_actors[i].set_xy(p)\n",
    "        else:\n",
    "            self.group_actors = [Polygon(current_state[g, :2]) for g in current_groups]\n",
    "        self.group_collection.set_paths(self.group_actors)\n",
    "\n",
    "    def plot_obstacles(self):\n",
    "        for s in self.scene.get_obstacles():\n",
    "            self.ax.plot(s[:, 0], s[:, 1], \"-o\", color=\"black\", markersize=2.5)\n",
    "\n",
    "    def animation_init(self):\n",
    "        self.plot_obstacles()\n",
    "        self.ax.add_collection(self.group_collection)\n",
    "        self.ax.add_collection(self.human_collection)\n",
    "        return (self.group_collection, self.human_collection)\n",
    "\n",
    "    def animation_update(self, i):\n",
    "        self.plot_groups(i)\n",
    "        self.plot_human(i)\n",
    "        return (self.group_collection, self.human_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MovieWriter imagemagick unavailable; using Pillow instead.\n"
     ]
    }
   ],
   "source": [
    "# initial states, each entry is the position, velocity and goal of a pedestrian in the form of (px, py, vx, vy, gx, gy)\n",
    "initial_state = np.array(\n",
    "        [\n",
    "            [0.1, 8, -0.5, -0.5, 11, 5],\n",
    "            [0.5, 8, -0.5, -0.5, 11, 5],\n",
    "            [0.2, 8, 0.0, 0.5, 11, 5],\n",
    "            [1.0, 0.1, 0.0, 0.5, 11, 5],\n",
    "            [2.0, 0.1, 0.0, 0.5, 11, 5],\n",
    "            [3.0, 0.1, 0.0, 0.5, 11, 5],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# social groups informoation is represented as lists of indices of the state array\n",
    "groups = [[1, 0],[3,4,5]]\n",
    "\n",
    "# list of linear obstacles given in the form of (x_min, x_max, y_min, y_max)\n",
    "obs = [[0,0,0,10], [0,10,10,10], [0,10,0,0], [10,10,0,4],[10,10,6,10],[6,6,4,6],[8,8,4,6],[6,8,4,4],[6,8,6,6]]\n",
    "\n",
    "\n",
    "s = Simulator(\n",
    "    initial_state,\n",
    "    groups=groups,\n",
    "    obstacles=obs,\n",
    ")\n",
    "s.step(50)\n",
    "output_dir = os.path.expanduser(\"~/Desktop/output_image\")\n",
    "with SceneVisualizer(s, output=output_dir) as sv:\n",
    "    sv.animate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
